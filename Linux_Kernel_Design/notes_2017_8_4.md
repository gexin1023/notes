# notes_2017_8_4

## 中断与中断处理

### 何为中断？
+ 一种由设备发向处理器的电信号
+ 中断不与处理器时钟同步，随时可以发生，内核随时可能因为中断到来而被打断。
+ 每一个中断都有唯一一个数字标志，称之为中断线（IRQ）
+ 异常是由软件产生，与处理器时钟同步。

### 中断处理程序
+ 由内核调用来响应中断
+ 运行于中断上下文
+ 中断的执行不可阻塞
+ 中断处理分为两个部分，中断处理程序是上半部（top half），还有下半部（bottom halves）

#### 中断处理程序注册
+ 中断处理程序是管理硬件驱动程序的组成部分，如果设备使用中断，其相应的驱动程序就会注册一个中断处理程序。
+ 通过request_irq（）函数来注册中断处理程序
```	
int request_irq( unsigned irq,
		irq_handler_t handler,
		unsigned long flags,
		count char* name,
		void *dev)
```
+ 第一个参数irq表示要分配的中断号
+ 第二个参数handler表示中断处理程序指针
+ 第三个表示标志，可以为0、IRQF_DISABLE、IRQF_SAMPLE_RANDOM、IRQF_TIMER、IRQF_SHARED
	+ **IRQF_DISABLE** 表示该中断处理期间，禁用所有其他中断
	+ **IRQF_SAMPLE_RANDOM** 这个设备产生的中断对内核熵池有贡献
	+ **IRQF_TIMER** 为系统定时器中断而准备的
	+ **IRQF_SHARED** 表示多个中断处理程序共享中断线。
+ 第四个参数name表示设备的文本表示
+ 第五个参数dev用于共享中断线，dev提供唯一的标志信息。

  需要注意的是，request_irq( )可能睡眠，因此不能再中断上下文或者其他不允许阻塞的代码中调用该函数。
### 中断处理程序释放
  卸载驱动程序时，需要用**free_irq（）**注销相应的中断处理程序，并释放中断线。

```
  void free_irq(unsigned int irq, void *dev);
```
如果指定的中断线不是共享的，那么该函数删除处理程序的同时将禁用这条中断线。如果是共享的，只删除dev对应的中断处理程序。
### 编写中断处理程序
```
static irqreturn_t intr_handler(int irq, void * dev);
```
  当一个给定的中断处理程序正在执行时，相应的中断线在所有的处理器上都会被屏蔽掉，以防止在同一条中断线上接受另一个新的中断。

## 中断上下文
+ 当执行一个中断时，内核处于中断上下文。
+ 中断上下文没有后备进程，不可以睡眠。
+ 中断上下文有着严格的时间限制，因为其打断了其他代码（有可能打断了其他中断处理程序）。中断上下文中的 代码应该迅速简洁，尽量不要使用循环去处理繁重的工作。

### 中断控制
Linux内核提供了一组接口用于控制机器上的中断状态

+ 禁止和激活中断
用于禁止、激活当前处理器的本地中断，
```
local_irq_disable();
local_irqenable();
```
+ 禁止指定中断线
```
void disable_irq(unsigned int irq);			//禁止控制器上某一条中断线，函数只有在当前执行的所有处理程序完成后，才能返回 
void disable_irq_nosync(unsigned int irq);	//禁止控制器上某一条中断线，不会等待当前中断处理程序执行完毕。
void enable_irq(unsigned int irq);			//激活控制器上某一条中断线， 
void synchronize_irq(unsigned int irq);		//等待下一个特定的中断处理程序退出
```
在一条中断线上，每次调用disable_irq_nosync()、disable_irq()，都需要调用一次enable_irq()，只有在enable_irq()完成了最后一次调用后，才完成了中断线的激活。

+ 这三个函数可以从中断或进程上下文中调用，而且不会睡眠。

## 下半部笔记
------

### 1. 软中断
#### 软中断实现
软中断是在编译期间静态分配，其结构如下所示，结构中包含一个接受该结构体指针作为参数的action函数。
```c
struct softirq_action{
    void (*action)(struct softirq_action *);
}
```
在kernel/softirq.c中定义了一个包含32个结构体的数组，每个数组成员都是一个被注册的软中断，数组如下所示：
```c
static struct softirq_action softirq_vec[NR_SOFTIRQS];
```
#### 软中断处理程序
软中断处理函数action原型如下：
```c
void siftirq_handler(struct softirq_action *);
```
内核通过如下的方式调用软中断处理函数：
```c
my_softirq->action(my_softirq);
```
软中断不会抢占其他软中断，唯一可以抢占软中断的是中断处理程序。
#### 软中断的执行
一个注册的软中断必须在被标记后才会被执行，软中断被唤起后，要在 do_softirq() 中执行，在do_softirq()函数中，遍历执行每一个被标记的软中断,如下所示：
```c
u32 pending;
//pending表示32位的标志，用来标记32个软中断，若位设置为1说明该位对应的软中断唤起。
pending = local_softirq_pending();

if(pending){
    struct softirq_action *h;
    
    set_softirq_pending(0);//重设置待处理的标志
    
    h = softirq_vec;
    do{
        if(pending&1)
            h->action(h);
        h++;
        pending>>1;
    }while(pending);
}
```
#### 软中断的使用
##### 1）分配索引
在编译期间，通过在<linux/interrupt.h>中定义枚举类型来声明软中断，如下所示，其中软中断按照优先高低自上而下，新插入新的软中断时需要根据想要的优先级插入相应位置。
```c
enum
{
	HI_SOFTIRQ=0,       //优先级高的tasklet
	TIMER_SOFTIRQ,
	NET_TX_SOFTIRQ,
	NET_RX_SOFTIRQ,
	BLOCK_SOFTIRQ,
	BLOCK_IOPOLL_SOFTIRQ,
	TASKLET_SOFTIRQ,    //正常优先级的tasklet
	SCHED_SOFTIRQ,
	HRTIMER_SOFTIRQ,
	RCU_SOFTIRQ,	/* Preferable RCU should always be the last softirq */

	NR_SOFTIRQS
};
```
##### 2）注册处理程序

可以通过open_softirq(）函数注册软中断处理程序，两个参数：软中断索引号、处理函数。
```c
open_softirq(NET_RX_SOFTIRQ, net_tx_action);
```
软中断处理程序执行时候，允许相应中断，但不能自己休眠。
在一个处理器运行时候，当前处理器上软中断被禁止。

##### 3）触发中断
raise_softirq()函数可以实现软中断设置为挂起待执行，该函数在运行之前需要先禁止中断，触发后再恢复原来的状态。如果中断本来就已经被禁止，可以采用raise_softirq_irqoff()函数去唤醒中断。
```c
raise_softirq(NET_RX_SOFTIRQ)；//需要在使用前关中断，然后再恢复。

raise_softirq_irqoff(NET_RX_SOFTIRQ);//适用于中断本来就已经被禁止的情况

```

### 2.tasklet
        tasklet是在软中断基础上实现的，相当于对软中断中的HI_SOFTIRQ、TASKLET_SOFTIRQ的更改，将tasklet链表加入到以上两个软中断的处理函数中执行。
        通常情况下，我们使用tasklet而不是软中断，使用软中断的情况屈指可数。
#### tasklet实现
##### tasklet结构
```cpp
struct tasklet_struct{
    struct tasklet_struct *next;    //链表中下一个tasklet
    unsigned long state;            //tasklet状态
    atomic_t count;                 //原子操作的计数器
    void (*func)(unsigned long);    //tasklet处理函数
    unsigned long data;             //给处理函数的参数
}
```
结构体重state成员，可以取0、TASKLET_STATE_RUN、TASKLET_STATE_SCHED。
    TASKLET_STATE_RUN->正在运行
    TASKLET_STATE_SCHED->已被调度

##### 调度
调度相当于将未调度的tasklet结构添加到两个链表结构：tasklet_vec(普通优先级)、tasklet_hi_vec(高优先级)。

```cpp
TASKLET_STATE_SCHED(); //tasklet调度函数

/*
 * 检查tasklet状态是否为TASKLET_STATE_SCHED，是的话已被调度，直接返回
 * 调用 __TASKLET_STATE_SCHED()函数
 * 保存中断状态，然后禁止中断状态
 * 将被调用的tasklet添加到tasklet链表
 * 唤醒软中断HI_SOFTIRQ或者TASKLET_SOFTIRQ
 * 恢复中断状态并返回
```

#### 使用tasklet
##### 1) 声明自己的tasklet

```CPP
DECLEAR_TASKLET(name, func, data)   //声明后tasklet处于激活状态
DECLEAR_TASKLET_DISABLE(name, func, data)//声明后tasklet处于禁止状态
```

##### 2） 编写tasklet处理程序

```
void tasklet_handler(unsigned long data)
```
因为tasklet是靠软中断实现的，因此不能睡眠，也就是说在tasklet处理函数中不能使用信号量或者其他阻塞式函数。

##### 3)调度自己的tasklet
我们可以通过tasklet_schedule()函数并传递给他相应的tasklet指针来调度，如下所示：
```
tasklet_schedule(&mytasklet); //将tasklet指针传过去，来调度
```
**要注意：tasklet总在调度他的处理器上执行。**

### 工作队列
工作队列可以把工作推后，交由一个内个线程去执行，这个下半部分总是会在进程上下文中执行。

#### 实现
工作队列最基本的是表现形式是把需要推后执行的任务交给特定的通用线程（工作队列也可以通过驱动程序创建工作者线程来处理推后工作，但是多数情况直接采用系统缺省的工作者线程来做推后工作）
#####  数据结构
1） 表示线程的数据结构
```
struct workqueue_struct{
    struct ypu_workqueue_struct cpu_wq[NR_CPUS];//数组每一项对应一个处理器
    struct list_head list;
    const char *name;
    int singlethread;
    int freezeable;
    int rt;
}
struct cpu_workqueue_struct{
    spinlock_t lock;// 锁来保护这种结构
    struct list_head worklist;//工作列表
    wait_queue_head_t more_work;
    struct workqueue_struct * wq;   //  关联工作队列结构
    task_t *thread;
    
}
```

注意：每一个工作者类型都关联一个自己的workqueue_struct.在该结构体里给每一个处理器（内的工作者线程）分配一个cpu_workqueue_struct。
2) 表示工作的数据结构

所有的工作者线程都是通过普通的内核线程实现的，他们都执行worker_thread()函数。在他们初始化完成以后，每个函数执行一个死循环并进入休眠，当有操作被传入队列里的时候，线程就会被唤醒，以执行这些操作。
    
  工作用work_struct结构体表示：
```
  struct work_struct{
        atomic_long_t data; //64位原子操作整数
        struct list_head enty;
        work_func_t func;
  }
```

这些结构体被连成链表，在每个处理器上的每种类型的队列都对应一个这样的链表。

#### 使用工作队列
##### 1）创建推后的工作
首先需要做的是创建一些需要推后完成的实际工作，通过宏DECLEAR_WORK在编译时静态创建结构体，如下所示：
```
DECLEAR_WORK(name; void(*func)(void*),void * data);
//这样会静态的创建一个名为name,处理函数为func，参数为data的结构体。
```
也可以在运行时通过指针创建一个工作，如下所示：
```
INIT_WORK(struct work_struct *work, void(*func), void *data);
//动态初始化一个由work指向的工作
```

##### 2）工作队列处理函数
```
void work_handler(void *data);//工作队列处理函数原型
```
这个函数会有工作者线程执行，因此函数运行于进程上下文中，默认情况下，允许相应中断，不能持有任和锁。
**需要注意的是，尽管操作函数运行于进程上下文中，但是他不能访问用户空间。**

#### 3）对工作进行调度

可以通过调用函数schedule_work() 把处理函数交给缺省的events工作线程
```
schedule_work(&work);
```
work马上就会被调度，一旦其所在的处理器上的工作者线程被唤醒，他就会被执行。
若不想work马上就工作，二十希望他进行一段延迟再执行，可以通过：
```
`schedule_delay_work(&work, delay);
//此时，直到delay的节拍时钟用完之后才会执行work
```
##### 4）刷新操作
进入队列的工作会在工作者线程的下一次被唤醒时候执行，在继续下一步工作之前，需要保证一些操作已经执行完毕。对于模块来说这一点很重要，在卸载之前，他可能需要调用以下函数。而在内核部分，为了防止竞争条件的出现，也可能需要确保不再持有处理工作。

出于以上目的，内核准备了一个用于刷新指定工作队列的函数
```
void flush_schedule_work(void);
```
函数会一直等待，直到队列中所有对象都被执行以后才会返回。
##### 5）创建新的工作队列
如果缺省的队列不能满足你的工作要求，需要创建新的工作队列与相应的工作者进程。由于这么做会在每个处理器上都创建一个工作者线程，所以只有在你明确了必须要自己创建一套线程来提高性能的情况下再创建自己的额工作队列。

这部分用的情况较少，需要的话再细看。


## Linux内核同步笔记

### 几个基本概念

	- 临界区（critical region）：访问和操作共享数据的代码段；
	- 原子操作：操作在执行中不被打断，要么不执行，要么执行完；
	- 竞争条件： 两个线程处于同一个临界区内执行，对数据同时访问或操作，称之为竞争；
	- 同步（synchronization）：避免并发和防止竞争条件成为同步。
	
### 预防死锁

	- 按顺序加锁，使用嵌套锁时，必须注意按顺序加锁，可以防止拥抱类死锁。
	- 防止饥饿
	- 不要重复请求同一个锁
	- 设计力求简单。
	
### 原子操作

原子操作可以保证执行过程不被打断，内核提供了两种原子操作接口：一组针对整数进行操作，另一组针对单独的位进行操作。

#### 原子整数操作

针对整数的操作只能对atomic_t类型的数据操作，atomic_t定义如下所示。
```
typedef struct{
	volatile int counter;
} atomic_t;
```

	尽管linux支持32整数，但是atomic_t类型只能当做24位来用，这是因为在SPARC体系结构上，原子操作的实现不同于其他系统，在int中的八位引入了一个锁来避免数据并发访问。

```
atomic_t v;						//	定义一个原子整数 v
atomic_t u = ATOMIC_INIT(0); 	//定义并初始化u

atomic_set(&v, 4);				//设置，赋值
atomic_add(2, &v);				//加
atomic_inc(&v);					//自增

atomic_read(&v);				//返回int型数据
```

原子操作通常是内联函数，往往是通过内嵌汇编指令来实现的。在编写代码时，能使用原子操作时，就尽量不要使用复杂的加锁机制。

#### 64位整数的原子操作

64位整数操作时，只需要讲atomic_前缀相关的类型及操作函数修改为 atomic64_前缀就可以了。

```
typedef struct{
	volatile long counter;
} atomic64_t;

atomic64_t v;						//	定义一个原子整数 v
atomic64_t u = ATOMIC_INIT(0); 	//定义并初始化u

atomic64_set(&v, 4);				//设置，赋值
atomic64_add(2, &v);				//加
atomic64_inc(&v);					//自增

atomic64_read(&v);				//返回int型数据
```

#### 原子位操作

位操作函数是针对普通地址进行操作的，无需特殊的原子类型，它的参数是一个指针和一个位号。32位系统上位号是0~31，64位系统上位号是0~63。

```
usigned long word = 0;

set_bit(0, &word);		//第0位被设置
set_bit(1, &word);		//第1位被设置

printk("%ul", &word);	//此处将打印3

clear_bit(1,&word);		//第1位被清除
change_bit(0, &word);	//第0位被翻转
```

### 自旋锁

自旋锁最多被一个可执行线程持有，如果一个线程试图获得一个已经被持有的自旋锁（即所谓的争用），那么该线程就会一直进行忙循环——旋转——等待锁重新可用。一个被争用的自旋锁使得请求它的线程在等待锁重新可用时自旋（自旋特别浪费处理器时间）。
	
	需要注意的是，自旋锁不应被长时间持有，自旋锁适用于短时间内进行轻量级加锁。

#### 自旋锁方法

```
DEFINE_SPIN;OCK(mr_lock);
spin_lock(&mr_lock);

/* 临界区
 * 操作共享数据的代码放于此处
 * 以避免对共享数据的操作并发
 */
 
spin_unlock(&mr_lock);
```

	需要注意，在单处理器机器上，编译的时候并不会加入自旋锁，它仅仅被当做一个设置内核抢占机制是否被启用的开关。如果禁止内核抢占，那么在编译时自旋锁会被完全踢出内核。
	
自旋锁可以在中断中使用，在中断中使用自旋锁时，要在使用之前首先禁止本地中断。否则，中断会打断正在持有锁的内核代码，有可能回去争用这个已经被持有的自旋锁，从而造成死锁。内核提供了同时禁止中断和获取锁的函数：
```
DEFINE_SPIN(mr_lock);
unsigned long flags;

spin_lock_irqsave(&mr_lock, flags);

//临界区（critical

spin_unlock_irqrestore(&mr_lock, flags);
```

	要对数据加锁，而不是对代码加锁。加锁保护的是临界区内的数据，而非代码。
	
除了上述静态方法添加自旋锁，还可以动态的添加。可以用spin_lock_init()函数动态创建自旋锁。

```
spin_lock();			//	获取指定的自旋锁
spin_lock_irq();		// 禁止本地中断，并获取自旋锁
spin_lock_irqsave();	// 获取本地中断状态，禁止本地中断，并获取自旋锁

spin_unlock();			// 释放指定的锁
spin_unlock_irq();		// 释放指定的锁，并打开中断
spin_unlock_irqrestore();// 释放指定锁，并将中断恢复的原有状态

spin_lock_init();		//	动态初始化指定的spinlock_t
spin_trylock();			// 试图获取指定的锁，若未获取就返回非0
spin_is_locked();		// 如果指定的锁正咋被获取，则返回非0，否则返回0
```

### 读写自旋锁

读取共享数据时，不会对数据造成改变，因此可以多个线程同时对数据进行读取。但是，写数据与读数据是不能同时的。

```
DEFINE_RWLOCK(mr_rwlock);

read_lock(&mr_rwlock);
// 临界区(只读)
read_unlock(&mr_rwlock);

write_lock(&mr_lock);
// 临界区(读写)，只能被一个线程获取
write_unlock(&mr_lock);

```

通常情况下，读锁和写锁处于完全分割的代码分支中。

```
read_lock();		// 获得指定的读锁
read_lock_irq();	// 禁止本地中断，并获取读锁
read_lock_irqsave();// 保存本地中断，禁止本地中断，获取读锁

read_unlock();		// 释放指定读锁
read_unlock_irq();	// 激活本地中断，并释放读锁
read_lock_irqstore();// 恢复中断到原有状态，并释放读锁

write_lock();		// 获得指定的写锁
write_lock_irq();	// 禁止本地中断，并获取写锁
write_lock_irqsave();// 保存本地中断，禁止本地中断，获取写锁

write_unlock();		// 释放指定写锁
write_unlock_irq();	// 激活本地中断，并释放写锁
write_lock_irqstore();// 恢复中断到原有状态，并释放写锁

write_trylock();	// 试图获取写锁，写锁不成功则返回非0值
rwlock_init();		// 初始化指定的rwlock
```
	
	需要注意的是，读写自旋锁照顾读锁更多一点，当读锁被占用时，写操作处于等待状态。但是，读锁却可以继续占用锁，大量的读锁被挂起，会导致写锁处于饥饿状态。

### 信号量

信号量是一种睡眠锁，如果有一个任务试图获得一个不可用的信号量时，信号量会将其推进一个等待队列。

	- 由于争优信号量的进程在等待时会睡眠，所以信号量适用于锁会被长时间锁定的情况。
	- 锁被短时间持有的情况不适合使用信号量，因为睡眠、维护等待队列以及唤醒所花费的时间可能比锁占用的时间还要长
	- 由于执行线程在锁被争用时会睡眠，所以只能在进程上下文中才能获取信号量锁，因为在中断上下文中是不可睡眠的。
	- 可以在持有锁时去睡眠，其他进程试图获取该锁时，并不会死锁，而是去睡眠了。
	- 占用信号量时不可以同时占用自旋锁，因为在等待信号量时有可能睡眠，而持有自旋锁时是不允许睡眠的。
	
#### 计数信号量和二值信号量

信号量可以同时允许任意数量的锁持有者，而自旋锁在一个时刻最多允许一个任务持有它，通过一个计数count来表示。只允许一个持有者的信号量称为二值信号量（也成为互斥信号量），其count为1。

Linux通过down()操作来请求获得一个信号量，down()对信号量计数减1，若结果大于等于0则持有该信号量，若小于0则线程被放入等待队列。临界区内操作完成之后，通过up()来释放信号量，信号量计数加1。

#### 创建和初始化信号量

```
struct semaphore name;		// 定义信号量
sema_init(&name, count);	// 初始化， count表示信号量的使用数量

```

创建互斥信号量可以用以下更简洁的方式
```
static DECLEAR_MUTEX(name);
```

更常见的情况是，信号量作为一个大数据结构动态创建。此时，只有指向该动态创建的信号量的简介指针，可以使用如下函数来对他进行初始化：
```
sama_init(sem, count);
```

动态初始化可以通过如下函数：
```
init_MUTEX(sem);
```

#### 使用信号量

通过函数**down_interruptible()**获取指定信号量，如果信号量不可用，就将调用进程设置成TASK_INTERRUPTIBLE状态进入睡眠。

使用down_trylock()函数可以尝试以堵塞的方式来获取指定的信号量。在信号已经被占领时，它返回非0值；否则返回0，并让你成功持有信号量锁。

```
static DECLEAR_MUTEX(mr_sem);	//定义并声明一个信号量锁

if(down_interruptible(&mr_sem)){
	
	//信号量未获取
}

/*	临界区... */

up(&mr_sem);	//释放给定的信号量

```

```
//信号量主要方法

sema_init(struct semaphore *, int);		// 以指定的计数值初始化动态创建信号量
init_MUTEX(struct semaphore *);			// 以计数值1初始化动态创建信号量
down_interruptible(struct semaphore *)  // 试图获取指定信号量，若信号被占用，则进入中断休眠状态
down(struct semaphore*)					// 试图获取指定信号量，若信号被占用，则进入不可中断睡眠状态
down_trylock(struct semaphore*)			// 试图获取指定信号量，若信号被争用，则立刻返回非0值
up(struct semaphore*)					// 释放信号量，如果睡眠队列不空，则唤醒其中一个任务	
```

### 读写信号量

与读写自旋锁类似，将信号量更具体为读写信号量。所有的读写信号量都是互斥信号量，他们只针对写操作互斥，不针对读者。也就是说，只要没有写锁定，并发的读锁数量不限。只要有写锁，就不可以有其他读锁或者写锁。

```
// 静态创建
static DECLEAR_RWSEM(name)

// 动态创建
init_rwsem(struct rw_semaphore * sem)

// 使用例子
static DECLEAR_RWSEM(mr_rwsem)；

down_read(&mr_rwsem);	//获取读信号量锁

// 临界区（只读）

up_read(&mr_rwsem);		//释放读信号量锁

down_write(&mr_rwsem);	// 获取写信号量锁

// 临界区（写）

up_write(&mr_rwsem);	// 释放写信号量锁

```

### 互斥体（mutex）

一种互斥的睡眠锁，其操作与计数为1的信号量相似，其接口更简单。

```
DEFINE_MUTEX(name);		// 静态初始化

mutex_init(&mutex);		// 动态初始化

mutex_lock(&mutex);		// 获取锁
	/* 临界区  */
mutex_unlock(&mutex);	// 释放锁

```

	- 任何时刻只有一个任务可以持有mutex
	- 给mutex上锁者必须负责给其解锁
	- 在同一个上下文中上锁和解锁
	- 当持有一个mutex时，进程不可以退出。
	- mutex不能在中断或者下半部中使用，即使是mutex_trylock()也不行
	- mutex只能通过官方API管理

	信号量和互斥体二者很相似，在使用时要优先使用mutex，只有在很特殊的场合才会使用信号量（一般在底层）。

### 完成变量（completion variable）

如果在内核中一个任务需要发出信号通知另一个任务发生了某个特定事件，可以利用完成变量使两个任务得以同步。

```
DECLEAR_COMPLETION(mr_comp);	// 静态初始化
init_completion(&mr_comp);		//动态创建

wait_for_completion(&mr_comp);	//等待某完成变量接受信号
complete(&mr_comp);				//发信号唤醒任何等待的任务

```

### 顺序锁

顺序锁的实现是通过一个序列计数器实现的，当有疑义的数据被写入之后，会得到一个锁，并且计数值增加。在读取数据前后，序列号都会被读取。如果读取的序列号值相同，说明在读操作过程中没有被写操作打断过。此外，如果序列数是偶数说明没有写操作发生，因为写锁会使值变成基数，读操作后值恢复到偶数。

```
seqlock_t mr_seq_lock = DEFINE_SEQLOCK(mr_seq_lock);

write_seqlock(&mr_seq_lock);
//写锁被读取
write_sequnlock(&mr_seq_lock);

// 写锁与自旋锁类似，差异在于读的时候
unsigned long seq;

do{
	seq = read_seqbegin(&mr_seq_lock);
	//开始读数据。。
}while(read_seqretry(&mr_seq_lock, seq));

```

### 禁止抢占

由于内核是抢占性的，内核的进程在任何时候都可以停下来执行更改优先权的进程，这意味着一个任务与被强占的任务可能在同一个临界区内运行。为了避免这种情况，内核抢占代码使用自旋锁作为非抢占区域的标志。如果一个自旋锁被持有，则内核不能进行抢占。

可以通过preempt_disable()来禁止内核抢占。

```
preempt_disable();
//内核禁止被抢占
preempt_enable();

```

### 顺序和屏障


## crt0,S(_main)代码分析
---
### 1. 设置sp寄存器地址
``` C
//设置SP栈指针
#if defined(CONFIG_SPL_BUILD) && defined(CONFIG_SPL_STACK)
	ldr	sp, =(CONFIG_SPL_STACK)
#else
	ldr	sp, =(CONFIG_SYS_INIT_SP_ADDR)
#endif

//设置地址八位对齐
#if defined(CONFIG_CPU_V7M)	/* v7M forbids using SP as BIC destination*/
	mov	r3, sp			   
	bic	r3, r3, #7		   //* 后三位清零相当于堆栈地址八位对齐
	mov	sp, r3				 
#else
	bic	sp, sp, #7	/* 8-byte alignment for ABI compliance */	
#endif
```
### 2. 在栈中为全局变量gd分配空间

```
// r0寄存器传递函数的参数
mov	r0, sp
bl	board_init_f_alloc_reserve	//在栈中为全局数据分配空间
mov	sp, r0		
//函数调用后返回值在r0中，将其保存到sp寄存器中	
//根据下面的board_init_f_alloc_reserve函数
//函数返回值为分配gb后的指针位置
```
board_init_f_alloc_reserve函数原型如下：
```
ulong board_init_f_alloc_reserve(ulong top)
{
	//将栈顶指针传进来，栈顶指针减去全局变量的长度意味着数据入栈，即在栈里预留变量存储空间。
	/* Reserve early malloc arena */
#if defined(CONFIG_SYS_MALLOC_F)
	top -= CONFIG_SYS_MALLOC_F_LEN;
#endif
	/* LAST : reserve GD (rounded up to a multiple of 16 bytes) */
	top = rounddown(top-sizeof(struct global_data), 16);
	return top;
}
```
### 3. 在栈中gd空间清零
```
	mov	r9, r0	//将栈顶指针存到r9寄存器里面,方便后续设置gd指针
	bl	board_init_f_init_reserve	//全局数据全部清零
```
board_init_f_init_reserve	函数定义如下：
```
void board_init_f_init_reserve(ulong base)
{
	struct global_data *gd_ptr;
#ifndef _USE_MEMCPY
	int *ptr;
#endif

	/*
	 * clear GD entirely and set it up.
	 * Use gd_ptr, as gd may not be properly set yet.
	 * 清除GD分配空间
	 */
	
	gd_ptr = (struct global_data *)base;
	/* zero the area */
#ifdef _USE_MEMCPY
	memset(gd_ptr, '\0', sizeof(*gd));	//全局数据区全部清零
#else
	for (ptr = (int *)gd_ptr; ptr < (int *)(gd_ptr + 1); )
		*ptr++ = 0;
#endif

	/* set GD unless architecture did it already */
#if !defined(CONFIG_ARM)
	arch_setup_gd(gd_ptr);
#endif
	/* next alloc will be higher by one GD plus 16-byte alignment */
	base += roundup(sizeof(struct global_data), 16);

	/*
	 * record early malloc arena start.
	 * Use gd as it is now properly set for all architectures.
	 */

#if defined(CONFIG_SYS_MALLOC_F)
	/* go down one 'early malloc arena' */
	gd->malloc_base = base;
	/* next alloc will be higher by one 'early malloc arena' size */
	base += CONFIG_SYS_MALLOC_F_LEN;
#endif
}
```

### 4. 调用board_init_f，初始化各种硬件

```
	mov	r0, #0
	bl	board_init_f	// jump to ==> board_f.c
```
在board_init_f函数中所进行的主要操作如下，其中init_sequence_f[ ]是一个数组，其内容为一系列初始化函数，在函数initcall_run_list中依次调用init_sequence_f数组的各个初始化函数。

```
void board_init_f(ulong boot_flags)
{
	//此处省略多行代码
	gd->flags = boot_flags;
	gd->have_console = 0;
	//通过调用initcall_run_list函数，执行各项初始化	
	if (initcall_run_list(init_sequence_f)) 
		hang();
}
```
initcall_run_list函数如下：
```
int initcall_run_list(const init_fnc_t init_sequence[])
{	
	const init_fnc_t *init_fnc_ptr;
	for (init_fnc_ptr = init_sequence; *init_fnc_ptr; ++init_fnc_ptr) {
		int ret;
		//此处省略很多代码
		//通过函数指针依次调用数组内函数
		ret = (*init_fnc_ptr)();		
	}
return 0;
}
```
数组init_sequence_f[ ]定义如下，每个成员为一个函数指针，函数参数为void，返回类型为int
```
static init_fnc_t init_sequence_f[] = {
#ifdef CONFIG_SANDBOX
	setup_ram_buf,
#endif
	setup_mon_len,
#ifdef CONFIG_OF_CONTROL
	fdtdec_setup,
#endif
#ifdef CONFIG_TRACE
	trace_early_init,
#endif
	initf_malloc,
	initf_console_record,
#if defined(CONFIG_MPC85xx) || defined(CONFIG_MPC86xx)
	/* TODO: can this go into arch_cpu_init()? */
	probecpu,
#endif
#if defined(CONFIG_X86) && defined(CONFIG_HAVE_FSP)
	x86_fsp_init,
#endif
	arch_cpu_init,		/* basic arch cpu dependent setup */
	mach_cpu_init,		/* SoC/machine dependent CPU setup */
	initf_dm,
	arch_cpu_init_dm,
	mark_bootstage,		/* need timer, go after init dm */
#if defined(CONFIG_BOARD_EARLY_INIT_F)
	board_early_init_f,
#endif
	/* TODO: can any of this go into arch_cpu_init()? */
#if defined(CONFIG_PPC) && !defined(CONFIG_8xx_CPUCLK_DEFAULT)
	get_clocks,		/* get CPU and bus clocks (etc.) */
#if defined(CONFIG_TQM8xxL) && !defined(CONFIG_TQM866M) \
		&& !defined(CONFIG_TQM885D)
	adjust_sdram_tbs_8xx,
#endif
	/* TODO: can we rename this to timer_init()? */
	init_timebase,
#endif
#if defined(CONFIG_ARM) || defined(CONFIG_MIPS) || \
		defined(CONFIG_BLACKFIN) || defined(CONFIG_NDS32) || \
		defined(CONFIG_SH) || defined(CONFIG_SPARC)
	timer_init,		/* initialize timer */
#endif
#ifdef CONFIG_SYS_ALLOC_DPRAM
#if !defined(CONFIG_CPM2)
	dpram_init,
#endif
#endif
#if defined(CONFIG_BOARD_POSTCLK_INIT)
	board_postclk_init,
#endif
#if defined(CONFIG_SYS_FSL_CLK) || defined(CONFIG_M68K)
	get_clocks,
#endif
	env_init,		/* initialize environment */
#if defined(CONFIG_8xx_CPUCLK_DEFAULT)
	/* get CPU and bus clocks according to the environment variable */
	get_clocks_866,
	/* adjust sdram refresh rate according to the new clock */
	sdram_adjust_866,
	init_timebase,
#endif
	init_baud_rate,		/* initialze baudrate settings */
	serial_init,		/* serial communications setup */
	console_init_f,		/* stage 1 init of console */
#ifdef CONFIG_SANDBOX
	sandbox_early_getopt_check,
#endif
	display_options,	/* say that we are here */
	display_text_info,	/* show debugging info if required */
#if defined(CONFIG_MPC8260)
	prt_8260_rsr,
	prt_8260_clks,
#endif /* CONFIG_MPC8260 */
#if defined(CONFIG_MPC83xx)
	prt_83xx_rsr,
#endif
#if defined(CONFIG_PPC) || defined(CONFIG_M68K) || defined(CONFIG_SH)
	checkcpu,
#endif
	print_cpuinfo,		/* display cpu info (and speed) */
#if defined(CONFIG_MPC5xxx)
	prt_mpc5xxx_clks,
#endif /* CONFIG_MPC5xxx */
#if defined(CONFIG_DTB_RESELECT)
	embedded_dtb_select,
#endif
#if defined(CONFIG_DISPLAY_BOARDINFO)
	show_board_info,
#endif
	INIT_FUNC_WATCHDOG_INIT
#if defined(CONFIG_MISC_INIT_F)
	misc_init_f,
#endif
	INIT_FUNC_WATCHDOG_RESET
#if defined(CONFIG_HARD_I2C) || defined(CONFIG_SYS_I2C)
	init_func_i2c,
#endif
#if defined(CONFIG_HARD_SPI)
	init_func_spi,
#endif
	announce_dram_init,
	/* TODO: unify all these dram functions? */
#if defined(CONFIG_ARM) || defined(CONFIG_X86) || defined(CONFIG_NDS32) || \
		defined(CONFIG_MICROBLAZE) || defined(CONFIG_AVR32) || \
		defined(CONFIG_SH)
	dram_init,		/* configure available RAM banks */
#endif
#if defined(CONFIG_MIPS) || defined(CONFIG_PPC) || defined(CONFIG_M68K)
	init_func_ram,
#endif
#ifdef CONFIG_POST
	post_init_f,
#endif
	INIT_FUNC_WATCHDOG_RESET
#if defined(CONFIG_SYS_DRAM_TEST)
	testdram,
#endif /* CONFIG_SYS_DRAM_TEST */
	INIT_FUNC_WATCHDOG_RESET

#ifdef CONFIG_POST
	init_post,
#endif
	INIT_FUNC_WATCHDOG_RESET
	/*
	 * Now that we have DRAM mapped and working, we can
	 * relocate the code and continue running from DRAM.
	 *
	 * Reserve memory at end of RAM for (top down in that order):
	 *  - area that won't get touched by U-Boot and Linux (optional)
	 *  - kernel log buffer
	 *  - protected RAM
	 *  - LCD framebuffer
	 *  - monitor code
	 *  - board info struct
	 */
	setup_dest_addr,
#if defined(CONFIG_BLACKFIN) || defined(CONFIG_XTENSA)
	/* Blackfin u-boot monitor should be on top of the ram */
	reserve_uboot,
#endif
#if defined(CONFIG_SPARC)
	reserve_prom,
#endif
#if defined(CONFIG_LOGBUFFER) && !defined(CONFIG_ALT_LB_ADDR)
	reserve_logbuffer,
#endif
#ifdef CONFIG_PRAM
	reserve_pram,
#endif
	reserve_round_4k,
#if !(defined(CONFIG_SYS_ICACHE_OFF) && defined(CONFIG_SYS_DCACHE_OFF)) && \
		defined(CONFIG_ARM)
	reserve_mmu,
#endif
#ifdef CONFIG_DM_VIDEO
	reserve_video,
#else
# ifdef CONFIG_LCD
	reserve_lcd,
# endif
	/* TODO: Why the dependency on CONFIG_8xx? */
# if defined(CONFIG_VIDEO) && (!defined(CONFIG_PPC) || defined(CONFIG_8xx)) && \
		!defined(CONFIG_ARM) && !defined(CONFIG_X86) && \
		!defined(CONFIG_BLACKFIN) && !defined(CONFIG_M68K)
	reserve_legacy_video,
# endif
#endif /* CONFIG_DM_VIDEO */
	reserve_trace,
#if !defined(CONFIG_BLACKFIN) && !defined(CONFIG_XTENSA)
	reserve_uboot,
#endif
#ifndef CONFIG_SPL_BUILD
	reserve_malloc,
	reserve_board,
#endif
	setup_machine,
	reserve_global_data,
	reserve_fdt,
	reserve_arch,
	reserve_stacks,
	setup_dram_config,
	show_dram_config,
#if defined(CONFIG_M68K) || defined(CONFIG_MIPS) || defined(CONFIG_PPC) || \
	defined(CONFIG_SH)
	setup_board_part1,
#endif
#if defined(CONFIG_PPC) || defined(CONFIG_M68K)
	INIT_FUNC_WATCHDOG_RESET
	setup_board_part2,
#endif
	display_new_sp,
#ifdef CONFIG_SYS_EXTBDINFO
	setup_board_extra,
#endif
	INIT_FUNC_WATCHDOG_RESET
	reloc_fdt,
	setup_reloc,
#if defined(CONFIG_X86) || defined(CONFIG_ARC)
	copy_uboot_to_ram,
	clear_bss,
	do_elf_reloc_fixups,
#endif
#if defined(CONFIG_XTENSA)
	clear_bss,
#endif
#if !defined(CONFIG_ARM) && !defined(CONFIG_SANDBOX)
	jump_to_copy,
#endif
	NULL,
};
```








